---
layout: archive
title: "Experience"
permalink: /
author_profile: true
redirect_from: 
  - /experience/
  - /experience.html
---

---

## AI Scientist Intern - [Neuralk-AI](https://www.neuralk-ai.com/)
<div style="display: flex; align-items: center;">
  <div style="flex: 1; text-align: justify; margin-right: 20px;">
    <p>4 months<br>
    May. 2025 - Aug. 2025<br>
    Contributed to the development of <a href="https://www.neuralk-ai.com/">Neuralk AI</a>’s Tabular Foundation Model (NICL) by improving upon state-of-the-art synthetic data generators and building a flexible library to optimize them. These generators produce the synthetic data used to pretrain NICL and play a key role in enabling the model to generalize across diverse tabular data use cases, powering high-impact enterprise applications in commerce and beyond.</p>
  </div>
  <div style="flex: 1;">
    <iframe src="https://www.linkedin.com/embed/feed/update/urn:li:share:7357056042989428736?collapsed=1" height="250" width="350" frameborder="0" allowfullscreen="" title="Post intégré"></iframe>
  </div>
</div>
[[GitHub](https://github.com/Neuralk-AI)]

---

## Research Internship - [ETHZ](https://ethz.ch/en.html)
5 months<br>
Apr. 2024 - Aug. 2024

<div style="flex: 1; text-align: justify; margin-right: 20px;">
    <p>I've done a five-month internship at the <a href="https://www.ini.uzh.ch/en/research/groups/EIS/Research.html">Institute of Neuroinformatics</a> in Zurich as an ETH Zurich student. My research focused on artificial neurogenesis in the context of hardware-constrained continual learning. Specifically, my team previously developed a neuromorphic hardware chip called <a href="https://www.nature.com/articles/s41467-023-44365-x">MOSAIC</a> for in-memory computing. I have been investigating the development of a neurogenesis approach to continual learning, designed to be implemented on MOSAIC chips.</p>
</div>

[[GitHub](https://github.com/Mathisnplus1/Master-Thesis)]

---

## Research Internship - [CNRS](https://www.cnrs.fr/fr)
3 months<br>
May 2023 - Jul 2023

<div style="flex: 1; text-align: justify; margin-right: 20px;">
    <p>The goal of this research internship was to delve deeper into research project below.
    <br><br>
    During a 3 months intenrship at <a href="https://home.cern/fr">CERN</a>, I conducted an in-depth investigation of Domain Adversarial Neural Networks, including a comparative review of various architectures and the refinement of the most relevant one to deal with highly imbalanced High Energy Physics datasets. More precisely, I embedded the domain information of each sample into the input space, which enabled the model greater flexibility in building the decision boundary.</p>
</div>

[[Paper](https://github.com/Mathisnplus1/fair-universe/blob/main/Internship/technical_report.pdf)] [[GitHub](https://github.com/Mathisnplus1/fair-universe/tree/main/Internship)]

---

## Research Project - [LBNL](https://www.lbl.gov/)
6 months<br>
Oct. 2022 - Mar. 2023

<div style="flex: 1; text-align: justify; margin-right: 20px;">
    <p>The <a href="https://fair-universe.lbl.gov/">Fair Universe</a> project primarily aims at mitigating systematic uncertainty in High Energy Physics through the elaboration of machine learning challenges.
    <br><br>
    I have been involved in this project part-time for a preliminary exploration of baselines to tackle systematic uncertainty. Additionnaly, I have been leading a team of 4 in the conception of a machine learning challenge which has been solved by students from a class of 20.</p>
</div>

[[Paper](/files/Fair_Universe_Toy_Challenge_Report.pdf)] [[GitHub](https://github.com/FairUniverseChallenge/FairUniverseChallenge)] [[Website](https://www.codabench.org/competitions/565/?secret_key=35329465-c378-4483-9564-8a4a4bf617ba)]

---